{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import os\n", "import sys \n", "from sklearn.linear_model import LinearRegression, LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.neural_network import MLPClassifier\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.decomposition import TruncatedSVD\n", "import copy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ead in movie watch data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainInfo = pd.read_csv('HW3/mv100k.train', sep='\\t', header=None)\n", "trainInfo.columns = [\n", "    \"user_id\", \"movie_id\", \"rating\", \"timestamp\"\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ovieInfo = pd.read_csv('HW3/info.item', sep='|', header=None)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["movieColumns = pd.read_csv('HW3/genres.item', sep='|', header=None)\n", "movieColumnsList1 = movieColumns[0].tolist()\n", "movieColumnsList2 = ['movie_id','movie_title','release_date', 'video_release_date','IMDb_URL']+movieColumnsList1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ead in movie info data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["movieInfo = pd.read_csv('HW3/info.item', sep='|', header=None, names=movieColumnsList2, encoding='latin-1')\n", "#print(movieInfo.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ead in user info data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["userInfo = pd.read_csv('HW3/info.user', sep='|', header=None)\n", "userInfo.columns = [\n", "    \"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\"\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ormalize age"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler()\n", "userInfo['age'] = scaler.fit_transform(userInfo[['age']])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ombine user and movie data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["combinedUserInfo = pd.merge(trainInfo[[\"user_id\", \"movie_id\", \"rating\",\"timestamp\"]], userInfo[[\"user_id\", \"age\", \"gender\", \"occupation\"]], on='user_id', how='left')\n", "combinedAllInfo = pd.merge(combinedUserInfo, movieInfo[['movie_id']+movieColumnsList1], on='movie_id', how='left')\n", "#one hot encode the data\n", "encodedInfo = pd.get_dummies(combinedAllInfo, columns=['user_id','movie_id','gender', 'occupation'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sort by timestamp then split into training and validation sets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["encodedSorted = encodedInfo.sort_values(by='timestamp')\n", "split_idx = int(len(encodedSorted) * 0.8)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train = encodedSorted.iloc[:split_idx]\n", "trainInput = train.drop(columns=[\"timestamp\",\"rating\"])\n", "trainOutput = train[\"rating\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validate = encodedSorted.iloc[split_idx:]\n", "validateInput = validate.drop(columns=[\"timestamp\",\"rating\"])\n", "validateOutput = validate[\"rating\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mplement SVD. This can be commentede out if not needed"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svd = TruncatedSVD(n_components=1500)  # Start with a large number\n", "svd.fit(trainInput)\n", "explained = np.cumsum(svd.explained_variance_ratio_)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot of SVD feature explained variance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(explained)\n", "plt.xlabel('Number of components')\n", "plt.ylabel('Cumulative explained variance')\n", "plt.title('Explained Variance vs. Number of Components')\n", "plt.grid()\n", "#plt.show()\n", "plt.savefig('HW3/SVDPlot.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit SVD with the chosen number of components"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["percentNeeded = 0.95\n", "n_components = np.argmax(explained >= percentNeeded) + 1\n", "print(f\"Number of components for {percentNeeded} explanation: {n_components}\")\n", "svd_final = TruncatedSVD(n_components=n_components)\n", "trainInput_svd = svd_final.fit_transform(trainInput)\n", "validateInput_svd = svd_final.transform(validateInput)\n", "print(f\"Reduced from {train.shape[1]} to {n_components} components.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert SVD output to be usable later"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svd_columns = [f'svd_{i}' for i in range(n_components)]\n", "trainInput = pd.DataFrame(trainInput_svd, index=train.index, columns=svd_columns)\n", "validateInput = pd.DataFrame(validateInput_svd, index=validate.index, columns=svd_columns)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mplement logistic regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logreg = LogisticRegression(penalty='l2', solver='liblinear',max_iter=300)\n", "logreg.fit(trainInput, trainOutput)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain on training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainPreds = logreg.predict(trainInput)\n", "train_rmse_logreg = np.sqrt(np.mean((trainPreds - trainOutput) ** 2))\n", "acc = accuracy_score(trainOutput, trainPreds)\n", "print(f\"Logistic Reg Train accuracy: {acc:.3f}, RMSE: {train_rmse_logreg:.3f}\")\n", "#validate on validation data\n", "validatePreds = logreg.predict(validateInput)\n", "validate_rmse_logreg = np.sqrt(np.mean((validatePreds - validateOutput) ** 2))\n", "acc = accuracy_score(validateOutput, validatePreds)\n", "print(f\"Logistic Reg Validation accuracy: {acc:.3f}, RMSE: {validate_rmse_logreg:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["repare data to be used in MLP"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainInput = trainInput.apply(pd.to_numeric)\n", "validateInput = validateInput.apply(pd.to_numeric)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainInput = trainInput.astype(float)\n", "validateInput = validateInput.astype(float)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = torch.tensor(trainInput.values, dtype=torch.float32)\n", "X_val = torch.tensor(validateInput.values, dtype=torch.float32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_train = torch.tensor(trainOutput.values - 1, dtype=torch.long)\n", "y_val = torch.tensor(validateOutput.values - 1, dtype=torch.long)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LP class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SimpleNN(nn.Module):\n", "    def __init__(self, input_dim, hidden_dim=100000, output_dim=5): \n", "        super(SimpleNN, self).__init__()\n", "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n", "        self.relu1 = nn.ReLU()\n", "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n", "        self.relu2 = nn.ReLU()\n", "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n", "    \n", "    def forward(self, x):\n", "        x = self.fc1(x)\n", "        x = self.relu1(x)\n", "        x = self.fc2(x)\n", "        x = self.relu2(x)\n", "        x = self.fc3(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["repare model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_dim = X_train.shape[1]\n", "output_dim = len(torch.unique(y_train))  \n", "model = SimpleNN(input_dim, hidden_dim=500, output_dim=output_dim)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()\n", "optimizer = optim.Adam(model.parameters(), lr=0.001)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(f\"Using device: {device}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.to(device)\n", "X_train = X_train.to(device)\n", "y_train = y_train.to(device)\n", "X_val = X_val.to(device)\n", "y_val = y_val.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_acc_list = []\n", "val_acc_list = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 2000\n", "best_val_acc = 0\n", "best_model_state = None\n", "epochs_since_improvement = 0\n", "patience = 50"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(epochs):\n", "    model.train()\n", "    optimizer.zero_grad()\n", "    outputs = model(X_train)\n", "    loss = criterion(outputs, y_train)\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    # Evaluation for each epoch\n", "    model.eval()\n", "    with torch.no_grad():\n", "        train_preds = model(X_train).argmax(dim=1)\n", "        train_acc = (train_preds == y_train).float().mean().item()\n", "        # Convert predictions and targets back to original rating scale (add 1)\n", "        train_preds_ratings = train_preds.cpu().numpy() + 1\n", "        y_train_ratings = y_train.cpu().numpy() + 1\n", "        train_rmse = np.sqrt(np.mean((train_preds_ratings - y_train_ratings) ** 2))\n", "        val_preds = model(X_val).argmax(dim=1)\n", "        val_acc = (val_preds == y_val).float().mean().item()\n", "        val_preds_ratings = val_preds.cpu().numpy() + 1\n", "        y_val_ratings = y_val.cpu().numpy() + 1\n", "        val_rmse = np.sqrt(np.mean((val_preds_ratings - y_val_ratings) ** 2))\n", "        train_acc_list.append(train_acc)\n", "        val_acc_list.append(val_acc)\n\n", "        # store RMSE for plotting\n", "        if epoch == 0:\n", "            train_rmse_list = []\n", "            val_rmse_list = []\n", "        train_rmse_list.append(train_rmse)\n", "        val_rmse_list.append(val_rmse)\n\n", "        # Save model if it's best so far\n", "        if val_acc > best_val_acc:\n", "            best_val_acc = val_acc\n", "            best_model_state = copy.deepcopy(model.state_dict())\n", "            epochs_since_improvement = 0\n", "            print(f\"New best model saved at epoch {epoch+1} with val accuracy: {val_acc:.3f}\")\n", "        else:\n", "            epochs_since_improvement += 1\n", "    #print progress\n", "    if (epoch+1) % 2 == 0:\n", "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, \"\n", "              f\"Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}, \"\n", "              f\"Train RMSE: {train_rmse:.3f}, Val RMSE: {val_rmse:.3f}\")\n", "    #allow for early stopping\n", "    if epochs_since_improvement >= patience:\n", "        print(f\"Early stopping at epoch {epoch+1} (no val acc improvement for {patience} epochs)\")\n", "        break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Training complete. Best validation accuracy: {best_val_acc:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the best model for evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Loading best model for evaluation...\")\n", "model.load_state_dict(best_model_state)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.eval()\n", "with torch.no_grad():\n", "    train_preds = model(X_train).argmax(dim=1)\n", "    train_acc = (train_preds == y_train).float().mean().item()\n", "    val_preds = model(X_val).argmax(dim=1)\n", "    val_acc = (val_preds == y_val).float().mean().item()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"PyTorch NN Train accuracy: {train_acc:.3f}, RMSE: {train_rmse:.3f}\")\n", "print(f\"PyTorch NN Validation accuracy: {val_acc:.3f}, RMSE: {val_rmse:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot RMSE curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,5))\n", "plt.plot(train_rmse_list, label='Train RMSE')\n", "plt.plot(val_rmse_list, label='Validation RMSE')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('RMSE')\n", "plt.title('Training and Validation RMSE')\n", "plt.legend()\n", "plt.savefig('HW3/rmse_curves.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot accuracy curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,5))\n", "plt.plot(train_acc_list, label='Train Accuracy')\n", "plt.plot(val_acc_list, label='Validation Accuracy')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('Accuracy')\n", "plt.title('Training and Validation Accuracy')\n", "plt.legend()\n", "plt.savefig('HW3/accuracy_curves.png', dpi=300)\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load and process test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["testInfo = pd.read_csv('HW3/mv100k.test', sep='\\t', header=None)\n", "testInfo.columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process test data the same way as training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["testCombinedUserInfo = pd.merge(testInfo[[\"user_id\", \"movie_id\", \"rating\",\"timestamp\"]], \n", "                               userInfo[[\"user_id\", \"age\", \"gender\", \"occupation\"]], \n", "                               on='user_id', how='left')\n", "testCombinedAllInfo = pd.merge(testCombinedUserInfo, \n", "                              movieInfo[['movie_id']+movieColumnsList1], \n", "                              on='movie_id', how='left')\n", "testEncoded = pd.get_dummies(testCombinedAllInfo, columns=['user_id','movie_id','gender', 'occupation'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Handle missing columns "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_cols = set(encodedInfo.columns)\n", "test_cols = set(testEncoded.columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_cols = train_cols - test_cols\n", "if missing_cols:\n", "    missing_df = pd.DataFrame(0, index=testEncoded.index, columns=list(missing_cols))\n", "    testEncoded = pd.concat([testEncoded, missing_df], axis=1)\n", "    testEncoded = testEncoded.copy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process test data similarly to how we processed the training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["testEncodedInput = testEncoded.drop(columns=[\"timestamp\", \"rating\"])\n", "testOutput = testEncoded[\"rating\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check if SVD is being used "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if 'svd_0' in trainInput.columns:\n", "    print(\"Applying SVD transformation to test data...\")\n", "    \n", "    # Handle columns that appear in test but not training data\n", "    train_feature_cols = trainInput.columns if 'svd_0' not in trainInput.columns else encodedInfo.drop(columns=[\"timestamp\", \"rating\"]).columns\n", "    common_cols = [col for col in testEncodedInput.columns if col in train_feature_cols]\n", "    missing_cols = [col for col in train_feature_cols if col not in testEncodedInput.columns]\n", "    \n", "    for col in missing_cols:\n", "        testEncodedInput[col] = 0\n", "        \n", "    testEncodedInput_filtered = testEncodedInput[train_feature_cols]\n", "    \n", "    # Apply SVD transformation\n", "    testInput_svd = svd_final.transform(testEncodedInput_filtered)\n", "    \n", "    # Convert to dataframe\n", "    testInput = pd.DataFrame(testInput_svd, index=testEncodedInput.index, \n", "                            columns=[f'svd_{i}' for i in range(n_components)])\n", "else:\n", "    testInput = testEncodedInput[[col for col in trainInput.columns if col in testEncodedInput.columns]]\n", "    \n", "# Ensure data types match training data\n", "testInput = testInput.apply(pd.to_numeric)\n", "testInput = testInput.astype(float)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Test logistic regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_preds_logreg = logreg.predict(testInput)\n", "test_rmse_logreg = np.sqrt(np.mean((test_preds_logreg - testOutput) ** 2))\n", "test_acc_logreg = accuracy_score(testOutput, test_preds_logreg)\n", "print(f\"Logistic Regression Test accuracy: {test_acc_logreg:.3f}, RMSE: {test_rmse_logreg:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Test MLP"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test = torch.tensor(testInput.values, dtype=torch.float32).to(device)\n", "y_test = torch.tensor(testOutput.values - 1, dtype=torch.long).to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.eval()\n", "with torch.no_grad():\n", "    test_preds = model(X_test).argmax(dim=1)\n", "    test_acc = (test_preds == y_test).float().mean().item()\n", "    test_preds_ratings = test_preds.cpu().numpy() + 1\n", "    y_test_ratings = y_test.cpu().numpy() + 1\n", "    test_rmse = np.sqrt(np.mean((test_preds_ratings - y_test_ratings) ** 2))\n", "    \n", "print(f\"PyTorch NN (Best Model) Test accuracy: {test_acc:.3f}, RMSE: {test_rmse:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a table"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results_data = [\n", "    ['Model', 'Train Acc', 'Val Acc', 'Test Acc', 'Train RMSE', 'Val RMSE', 'Test RMSE'],\n", "    ['Logistic Regression', f\"{accuracy_score(trainOutput, trainPreds):.3f}\", \n", "     f\"{accuracy_score(validateOutput, validatePreds):.3f}\", f\"{test_acc_logreg:.3f}\", \n", "     f\"{train_rmse_logreg:.3f}\", f\"{validate_rmse_logreg:.3f}\", f\"{test_rmse_logreg:.3f}\"],\n", "    ['Neural Network', f\"{train_acc:.3f}\", f\"{val_acc:.3f}\", f\"{test_acc:.3f}\", \n", "     f\"{train_rmse:.3f}\", f\"{val_rmse:.3f}\", f\"{test_rmse:.3f}\"]\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(12, 3))\n", "ax.axis('off')\n", "ax.axis('tight')\n", "table = ax.table(cellText=results_data[1:], colLabels=results_data[0], \n", "                loc='center', cellLoc='center')\n", "table.auto_set_font_size(False)\n", "table.set_fontsize(12)\n", "table.scale(1, 1.5)  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.tight_layout()\n", "plt.savefig('HW3/results_table.png', dpi=300, bbox_inches='tight')\n", "plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save results to CSV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results_df = pd.DataFrame(results_data[1:], columns=results_data[0])\n", "results_df.to_csv('HW3/results_summary.csv', index=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Results saved\")\n", "print(\"done\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}